{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca33ae2-7227-493e-ac51-107eb58e6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import findspark\n",
    "\n",
    "# Point findspark to your Spark installation directory\n",
    "findspark.init('/opt/spark')  \n",
    "\n",
    "# Use the Python interpreter from your current virtual environment\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9479f98-92a9-4888-948e-77a228a58973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/21 09:01:32 WARN Utils: Your hostname, sandeep-VMware-Virtual-Platform resolves to a loopback address: 127.0.1.1; using 192.168.161.128 instead (on interface ens33)\n",
      "25/05/21 09:01:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/21 09:01:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import udf, avg, count\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"SentimentEngagementApp\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39fdcadd-ef60-47e8-a400-d8772167d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |1467810672|Mon Apr 06 22:19:49 PDT 2009|NO_QUERY|scotthamilton  |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
      "|0  |1467810917|Mon Apr 06 22:19:53 PDT 2009|NO_QUERY|mattycus       |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
      "|0  |1467811184|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|ElleCTF        |my whole body feels itchy and like its on fire                                                                     |\n",
      "|0  |1467811193|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|Karoli         |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
      "|0  |1467811372|Mon Apr 06 22:20:00 PDT 2009|NO_QUERY|joy_wolf       |@Kwesidei not the whole crew                                                                                       |\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_path = \"hdfs:///socialmedia/socialmedia.csv\"  # Change to your HDFS path\n",
    "\n",
    "df = spark.read.csv(input_path, header=True, inferSchema=True)\n",
    "df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370f7ad9-22da-4ddf-bfe9-43b364601f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"sentiment\",\"id\",\"date\",\"Query\",\"User\",\"text\"]\n",
    "df = df.toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d44897-b3d6-4907-8771-6bcbaf56309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865997ff-f3eb-496b-b4fd-65829f010155",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    if text is None:\n",
    "        return \"neutral\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "sentiment_udf = udf(vader_sentiment, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75dfa3b1-fc88-4207-acea-64995a8549cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|user           |text                                                                                                           |vader_sentiment|\n",
      "+---------------+---------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|scotthamilton  |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!|negative       |\n",
      "|mattycus       |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                      |positive       |\n",
      "|ElleCTF        |my whole body feels itchy and like its on fire                                                                 |negative       |\n",
      "|Karoli         |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. |negative       |\n",
      "|joy_wolf       |@Kwesidei not the whole crew                                                                                   |neutral        |\n",
      "|mybirch        |Need a hug                                                                                                     |positive       |\n",
      "|coZZ           |@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?            |positive       |\n",
      "|2Hood4Hollywood|@Tatiana_K nope they didn't have it                                                                            |neutral        |\n",
      "|mimismo        |@twittera que me muera ?                                                                                       |neutral        |\n",
      "|erinx3leannexo |spring break in plain city... it's snowing                                                                     |neutral        |\n",
      "+---------------+---------------------------------------------------------------------------------------------------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 4) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+\n",
      "|           user|total_queries|\n",
      "+---------------+-------------+\n",
      "|     megan_rice|           15|\n",
      "|        Daniiej|            3|\n",
      "|         MeghTW|            1|\n",
      "|   candicebunny|            1|\n",
      "|stranger_danger|           14|\n",
      "+---------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"vader_sentiment\", sentiment_udf(df[\"text\"]))\n",
    "\n",
    "df.select(\"user\", \"text\", \"vader_sentiment\").show(10, truncate=False)\n",
    "\n",
    "# User engagement: avg session_time is missing? Use count of queries/comments per user\n",
    "user_engagement = df.groupBy(\"user\").agg(\n",
    "    count(\"query\").alias(\"total_queries\")\n",
    ")\n",
    "\n",
    "user_engagement.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf6ca576-e4e2-444a-874e-b3e3d7de17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------------+\n",
      "|         user|total_queries|majority_sentiment|\n",
      "+-------------+-------------+------------------+\n",
      "|      Daniiej|            3|          negative|\n",
      "|     J_Moneyy|            7|          positive|\n",
      "|  Lilli_Allen|            1|           neutral|\n",
      "|       MeghTW|            1|          negative|\n",
      "|      SoEdith|            5|          negative|\n",
      "|      caaaami|            1|          negative|\n",
      "| candicebunny|            1|           neutral|\n",
      "|   convoy3571|           13|          positive|\n",
      "|divingkid2001|            1|           neutral|\n",
      "|   megan_rice|           15|          positive|\n",
      "+-------------+-------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, desc\n",
    "\n",
    "window = Window.partitionBy(\"user\").orderBy(desc(\"count\"))\n",
    "\n",
    "sentiment_counts = df.groupBy(\"user\", \"vader_sentiment\").count()\n",
    "ranked = sentiment_counts.withColumn(\"rank\", row_number().over(window))\n",
    "majority_sentiment = ranked.filter(ranked.rank == 1).select(\"user\", ranked.vader_sentiment.alias(\"majority_sentiment\"))\n",
    "\n",
    "# Join engagement and majority sentiment\n",
    "final_df = user_engagement.join(majority_sentiment, on=\"user\", how=\"left\")\n",
    "\n",
    "final_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfba2122-8c38-4437-9efc-a830f5e41bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.477, 'pos': 0.523, 'compound': 0.6588}\n"
     ]
    }
   ],
   "source": [
    "print(analyzer.polarity_scores(\"This is a great day!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7b4e5e-f767-4fc5-bd51-dd47ffde927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/21 09:04:50 WARN DAGScheduler: Broadcasting large task binary with size 1098.5 KiB\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to hdfs:///user/sandeep/output/vader_sentiment_engagement\n"
     ]
    }
   ],
   "source": [
    "output_path = \"hdfs:///user/sandeep/output/vader_sentiment_engagement\"\n",
    "final_df.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "print(f\"Saved results to {output_path}\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6629775a-590e-4ed9-9674-b08e587451c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a742c6b-4e3b-4fb5-8920-5124d5f87c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
